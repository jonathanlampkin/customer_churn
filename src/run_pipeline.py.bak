"""
Complete Machine Learning Pipeline for Churn Prediction
Logs and visualizes each step of the process
"""

import sys
import os
import time
import logging
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import yaml
from pathlib import Path
import json
import argparse
from sklearn.linear_model import LogisticRegression
import xgboost as xgb
import lightgbm as lgb
from sklearn.ensemble import StackingClassifier

# Add project root to Python path
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# Set up logging with both file and console output
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('pipeline.log'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)

def create_directories():
    """Create all required directories for the project"""
    dirs = [
        'data/raw',
        'data/interim',
        'data/processed',
        'models',
        'reports/figures',
        'reports/metrics',
        'logs'
    ]
    
    for d in dirs:
        os.makedirs(d, exist_ok=True)
        logger.info(f"Created directory: {d}")

def run_data_processing(data_path=None):
    """Process raw data into features for training"""
    logger.info("Loading and processing data...")
    
    try:
        if data_path and data_path.endswith('.arff'):
            # Handle ARFF data directly instead of using ChurnDataProcessor
            from scipy.io import arff
            import pandas as pd
            from sklearn.model_selection import train_test_split
            
            logger.info(f"Loading ARFF data from: {data_path}")
            data, meta = arff.loadarff(data_path)
            
            # Convert to pandas DataFrame
            df = pd.DataFrame(data)
            
            # Convert byte strings to regular strings (common in ARFF files)
            for col in df.select_dtypes(include=['object']).columns:
                df[col] = df[col].str.decode('utf-8')
            
            logger.info(f"Data loaded successfully: {df.shape[0]} rows, {df.shape[1]} columns")
            
            # Identify target column (likely "churn" or similar)
            target_column = None
            for col in df.columns:
                if 'churn' in col.lower():
                    target_column = col
                    break
            
            if not target_column:
                # Default to the last column if we can't find an explicit churn column
                target_column = df.columns[-1]
                logger.info(f"No column with 'churn' in name found, using last column: {target_column}")
            else:
                logger.info(f"Using '{target_column}' as target column")
            
            # Prepare features and target
            X = df.drop(columns=[target_column])
            y = df[target_column]
            
            # Split the data
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
            logger.info(f"Training set: {X_train.shape[0]} rows, Test set: {X_test.shape[0]} rows")
            
            # Save processed data to interim folder for other pipeline stages
            os.makedirs('data/interim', exist_ok=True)
            X_train.to_csv('data/interim/X_train.csv', index=False)
            X_test.to_csv('data/interim/X_test.csv', index=False)
            y_train.to_csv('data/interim/y_train.csv', index=False)
            y_test.to_csv('data/interim/y_test.csv', index=False)
            
            return X_train, X_test, y_train, y_test
        else:
            # Use existing ChurnDataProcessor for non-ARFF data
            from src.data.data_processor import ChurnDataProcessor
            processor = ChurnDataProcessor()
            return processor.process_data()
    except Exception as e:
        logger.error(f"Error in data processing: {str(e)}")
        import traceback
        logger.error(traceback.format_exc())
        raise

def run_feature_engineering(X_train, X_test, y_train, y_test):
    """Run the feature engineering pipeline"""
    logger.info("=" * 80)
    logger.info("STARTING FEATURE ENGINEERING")
    logger.info("=" * 80)
    
    from src.features.feature_engineering import FeatureEngineer
    
    # Start timer
    start_time = time.time()
    
    # Initialize engineer
    engineer = FeatureEngineer()
    engineer.set_data(X_train, X_test, y_train, y_test)
    
    # Run the feature engineering pipeline
    logger.info("Running feature engineering pipeline...")
    X_train_eng, X_test_eng = engineer.run_feature_engineering_pipeline()
    
    # Log completion
    engineering_time = time.time() - start_time
    logger.info(f"Feature engineering completed in {engineering_time:.2f} seconds")
    
    return X_train_eng, X_test_eng, y_train, y_test

def run_model_training(X_train, X_test, y_train, y_test):
    """Run the model training pipeline"""
    logger.info("=" * 80)
    logger.info("STARTING MODEL TRAINING")
    logger.info("=" * 80)
    
    from src.models.model_trainer import ModelTrainer
    
    # Start timer
    start_time = time.time()
    
    # Initialize trainer
    trainer = ModelTrainer()
    trainer.set_data(X_train, X_test, y_train, y_test)
    
    # Compare different approaches to class imbalance
    logger.info("Comparing class imbalance handling approaches...")
    imbalance_results = trainer.compare_class_imbalance_approaches()
    
    with open('reports/metrics/imbalance_comparison.json', 'w') as f:
        json.dump(imbalance_results, f, indent=4)
    
    # Train and compare models
    logger.info("Training and comparing models...")
    comparison_results = trainer.train_and_compare_models()
    
    with open('reports/metrics/model_comparison.json', 'w') as f:
        json.dump(comparison_results, f, indent=4)
    
    # Get holistic model metrics (including interpretability, complexity)
    logger.info("Evaluating models holistically...")
    holistic_results = trainer.evaluate_models_holistically()
    
    with open('reports/metrics/holistic_evaluation.json', 'w') as f:
        json.dump(holistic_results, f, indent=4)
    
    # Select best model based on multiple criteria
    logger.info("Selecting best model...")
    best_model_name, selection_criteria = trainer.select_best_model(holistic_results)
    
    logger.info(f"Selected model: {best_model_name}")
    logger.info(f"Selection criteria: {selection_criteria}")
    
    # Fine-tune best model
    logger.info(f"Fine-tuning {best_model_name}...")
    tuning_results = trainer.tune_best_model()
    
    with open('reports/metrics/hyperparameter_tuning.json', 'w') as f:
        json.dump(tuning_results, f, indent=4)
    
    # Train final model
    logger.info("Training final model...")
    final_metrics = trainer.train_final_model()
    
    with open('reports/metrics/final_model_metrics.json', 'w') as f:
        json.dump(final_metrics, f, indent=4)
    
    # Log completion
    training_time = time.time() - start_time
    logger.info(f"Model training completed in {training_time:.2f} seconds")
    
    return trainer.best_model, final_metrics

def run_model_explanation(model, X_test, y_test):
    """Run the model explanation pipeline"""
    logger.info("=" * 80)
    logger.info("STARTING MODEL EXPLANATION")
    logger.info("=" * 80)
    
    from src.models.model_explainer import ModelExplainer
    
    # Start timer
    start_time = time.time()
    
    # Initialize explainer
    explainer = ModelExplainer()
    explainer.set_model_and_data(model, X_test, y_test)
    
    # Generate explanations
    logger.info("Generating global feature importance...")
    importance_df = explainer.global_feature_importance()
    importance_df.to_csv('reports/metrics/feature_importance.csv', index=False)
    
    logger.info("Generating SHAP explanations...")
    shap_values = explainer.calculate_shap_values()
    
    logger.info("Generating sample explanations...")
    sample_explanations = explainer.generate_sample_explanations(10)
    
    with open('reports/metrics/sample_explanations.json', 'w') as f:
        json.dump(sample_explanations, f, indent=4)
    
    # Log completion
    explanation_time = time.time() - start_time
    logger.info(f"Model explanation completed in {explanation_time:.2f} seconds")

def main():
    """Run the complete machine learning pipeline"""
    start_time = time.time()
    logger.info("=" * 80)
    logger.info("STARTING COMPLETE ML PIPELINE")
    logger.info("=" * 80)
    
    # Parse command-line arguments
    parser = argparse.ArgumentParser(description='Run ML pipeline')
    parser.add_argument('--data_path', type=str, help='Path to the data file')
    args = parser.parse_args()
    
    # Create necessary directories
    create_directories()
    
    try:
        # Process data
        logger.info("=" * 80)
        logger.info("STARTING DATA PROCESSING")
        logger.info("=" * 80)
        X_train, X_test, y_train, y_test = run_data_processing(args.data_path)
        
        # Run feature engineering
        X_train_eng, X_test_eng, y_train, y_test = run_feature_engineering(X_train, X_test, y_train, y_test)
        
        # Run model training
        best_model, final_metrics = run_model_training(X_train_eng, X_test_eng, y_train, y_test)
        
        # Run model explanation
        run_model_explanation(best_model, X_test_eng, y_test)
        
        # Log completion
        pipeline_time = time.time() - start_time
        logger.info("=" * 80)
        logger.info(f"COMPLETE PIPELINE FINISHED in {pipeline_time:.2f} seconds")
        logger.info("=" * 80)
        logger.info(f"Final model performance: {final_metrics}")
        
        # Generate dashboard visuals
        logger.info("Generating dashboard visuals...")
        from src.dashboard.create_demo_visuals import create_all_visuals
        create_all_visuals()
        
        logger.info("Pipeline completed successfully!")
        
    except Exception as e:
        logger.error(f"Pipeline failed with error: {str(e)}")
        return

if __name__ == "__main__":
    main() 